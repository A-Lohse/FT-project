document.body.removeChild(link);
}"))))
# read only columns
if ("record_id" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
if ("policy_id" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
if ("corrected" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
if ("ra_name" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
if ("recorded_date" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
if ("source_file_Type" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
if ("source_file_2_Type" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
if ("link_type" %in% input$col_names) {
policydf <- policydf %>%
hot_col("record_id", readOnly = TRUE)
}
# columns with features
if ("Correct" %in% input$col_names) {
policydf <- policydf %>%
hot_col(c("Correct"),
renderer = htmlwidgets::JS("safeHtmlRenderer"),
readOnly = TRUE)
}
if ("Update" %in% input$col_names) {
policydf <- policydf %>%
hot_col(c("Update"),
renderer = htmlwidgets::JS("safeHtmlRenderer"),
readOnly = TRUE)
}
if ("type" %in% input$col_names) {
policydf <- policydf %>%
hot_col("type", type = "dropdown",
strict = TRUE, source = source_cols$type)
}
if ("country" %in% input$col_names) {
policydf <- policydf %>%
hot_col("country", type = "autocomplete",
strict = TRUE, source = source_cols$country)
}
if ("province" %in% input$col_names) {
policydf <- policydf %>%
hot_col("province", type = "autocomplete",
strict = TRUE, source = source_cols$province)
}
if ("target_geog_level" %in% input$col_names) {
policydf <- policydf %>%
hot_col("target_geog_level", type = "dropdown",
strict = TRUE, source = source_cols$target_geog_level)
}
if ("target_who_what" %in% input$col_names) {
policydf <- policydf %>%
hot_col("target_who_what", type = "dropdown",
strict = TRUE, source = source_cols$target_who_what)
}
if ("target_direction" %in% input$col_names) {
policydf <- policydf %>%
hot_col("target_direction", type = "dropdown",
strict = TRUE, source = source_cols$target_direction)
}
if ("compliance" %in% input$col_names) {
policydf <- policydf %>%
hot_col("compliance", type = "dropdown",
strict = TRUE, source = source_cols$compliance)
}
return(policydf)
})
## -----------------< output$text -- selected record IDs >--------------------
output$text <- renderText({
recordstext <- ifelse(length(record_select$id) == 0, 'None selected.',
paste0(unique(record_select$id), collapse = ', '))
paste0("<b>Records Selected from timeline viz:</b> ", recordstext)
})
# upload information to SQL table whenever outcome button clicked
# observeEvent(input$qualtrics,{
#   tibble(userid=this_user,
#          clicktime=lubridate::now()) %>%
#     dbWriteTable(con,"webout",value=.,overwrite=F,append=T,row.names=F)
# })
# updateSelectizeInput(session, 'ind', choices = bea_desc$NAICS.Desc, server = TRUE,
#                      selected=bea_desc$NAICS.Desc[1])
}
###################################################
# CoronaNet Data Validation Web App
# global file for loading global data/options
# Author(s): Robert Kubinec, Clara Wang
# Last updated: June 23, 2020
###################################################
## ---------------------< load data >--------------------------------
# database connection
con <- connect_cnetdb()
# read in data from AWS
raw_data <- dbReadTable(con, "cordata")
## ---------------------< format AWS tables >--------------------------------
# need to check and see if all column names exist in the update table
exist_update <- dbGetQuery(con, "SELECT * FROM public.corupdate LIMIT 1")
missing_cols <- names(raw_data)[!(names(raw_data) %in% names(exist_update))]
# loop over missing cols and add them to table corupdate
fix_miss <- lapply(missing_cols, function(m) {
# determine column type in SQL
this_col_type <- dbDataType(dbDriver("PostgreSQL"), raw_data[[m]])
dbSendQuery(con, paste0("ALTER TABLE corupdate ADD COLUMN ",
make.db.names(dbDriver("PostgreSQL"), m),
" ", this_col_type, ";"))
})
## -------------------< format policy tab data >--------------------------------
# data for populating the table
full_data <- raw_data %>%
mutate(group_id = as.numeric(factor(type)),
type2 = str_wrap(type, width = 15),
start = ymd(start),
end = ymd(end),
date_announced = ymd(date_announced),
type2 = str_replace_all(type2, "\\n","<br>")) %>%
# grab corrections and updates to policies
mutate(
Correct = paste0(
'<a href="https://tummgmt.eu.qualtrics.com/jfe/form/SV_bf6YMWbTpYJAW4l?Q_R=',
record_id,
'&Q_R_DEL=1&record_id=',
policy_id, '&link_type=C"',
' target="_blank">Correct</a>'),
# only create update link if it's a new entry
Update = ifelse(
entry_type == "new_entry",
paste0('<a href="https://tummgmt.eu.qualtrics.com/jfe/form/SV_bf6YMWbTpYJAW4l?Q_R=',
record_id, '&record_id=',
policy_id,'&link_type=U"',' target="_blank">Update</a>'), ""),
recorded_date = as.character(recorded_date)) %>%
select(Correct, Update,
corrected,
start, end,
record_id, policy_id,
recorded_date,
ra_name, country, province,
init_country_level, entry_type,
type, description,
target_geog_level, target_region, target_province, target_city,
target_other, target_who_what, target_direction, travel_mechanism,
compliance, enforcer, everything())
## -------------------< format timeline data >--------------------------------
# policy type information
group_data <- select(full_data, id = "group_id", content = "type2", type) %>%
distinct() %>%
filter(!is.na(id))
# timeline data
qdata <- full_data %>%
select(start,
end,
ra_name,
policy_id,
title = "description",
content = "init_country_level",
group = "group_id",
id = "record_id",
country,
province,
city,
entry_type) %>%
mutate(
content = recode(
content,
`No, it is at the national level` = "National",
`Yes, it is at the province/state level` = "Provincial",
`Yes, it is at the city/municipal level` = "City",
`Yes, it is at another governmental level (e.g. county)` = "District"),
end = coalesce(end, lubridate::today()),
content = case_when(
!is.na(province) & is.na(city) ~ paste(content, country,
province, title, sep = "-"),
!is.na(province) & !is.na(city) ~ paste(content, country,
province, title, city, sep = "-"),
is.na(province) & !is.na(city) ~ paste(content, country,
city, sep = "-"),
TRUE ~ paste(content, country, title, sep = "-"))) %>%
filter(!is.na(start), !is.na(group))
# set up policy types for drop downs to ensure data entry is safe
source_cols <- purrr::map(
.x = purrr::set_names(c("type", "country", "province", "target_geog_level",
"compliance", "target_who_what", "target_direction")),
.f = function(x) unique(full_data[[x]]))
# grab most recent entry in data
mostrecent_date <- max(lubridate::as_datetime(full_data$recorded_date),
na.rm = TRUE)
# disconnect from database
dbDisconnect(con)
# user_access_data <- tibble(userid=session$user,
#        accessdate=as.character(lubridate::now()))
# dbWriteTable(con,"corona_users",value=user_access_data,append=T,
#              row.names=F)
update <- environment()
update$count <- 0
###################################################
# CoronaNet Data Validation Web App
# RShiny app for updating RA entries
# Author(s): Robert Kubinec, Clara Wang
# Last updated: June 23, 2020
###################################################
#### SET UP --------------------------------------------------------------------
# set working directory
#wd <- "C:/Users/clara/Documents/corona_private/data_validate_shiny" # Clara wd
#setwd(wd)
# load libraries
library(shiny)
library(shinythemes)
library(dplyr)
library(tidyr)
library(shinyWidgets)
library(RPostgreSQL)
library(timevis)
library(stringr)
library(lubridate)
library(rhandsontable)
library(shinyalert)
library(readr)
require(DBI)
# source required files
source("utils.R")   # load functions
source("global.R")  # load data
source("ui.R")      # app UI
source("server.R")  # app server
#### RUN APP -------------------------------------------------------------------
# disconnect from AWS database when Shiny app closes
onStop(function() {
dbDisconnect(con)
})
# run Shiny App
shinyApp(
ui = ui,
server = server
)
###################################################
# CoronaNet Data Validation Web App
# global file for loading global data/options
# Author(s): Robert Kubinec, Clara Wang
# Last updated: June 23, 2020
###################################################
## ---------------------< load data >--------------------------------
# database connection
con <- connect_cnetdb()
# read in data from AWS
raw_data <- dbReadTable(con, "cordata")
## ---------------------< format AWS tables >--------------------------------
# need to check and see if all column names exist in the update table
exist_update <- dbGetQuery(con, "SELECT * FROM public.corupdate LIMIT 1")
missing_cols <- names(raw_data)[!(names(raw_data) %in% names(exist_update))]
# loop over missing cols and add them to table corupdate
fix_miss <- lapply(missing_cols, function(m) {
# determine column type in SQL
this_col_type <- dbDataType(dbDriver("PostgreSQL"), raw_data[[m]])
dbSendQuery(con, paste0("ALTER TABLE corupdate ADD COLUMN ",
make.db.names(dbDriver("PostgreSQL"), m),
" ", this_col_type, ";"))
})
## -------------------< format policy tab data >--------------------------------
# data for populating the table
full_data <- raw_data %>%
mutate(group_id = as.numeric(factor(type)),
type2 = str_wrap(type, width = 15),
start = ymd(start),
end = ymd(end),
date_announced = ymd(date_announced),
type2 = str_replace_all(type2, "\\n","<br>")) %>%
# grab corrections and updates to policies
mutate(
Correct = paste0(
'<a href="https://tummgmt.eu.qualtrics.com/jfe/form/SV_bf6YMWbTpYJAW4l?Q_R=',
record_id,
'&Q_R_DEL=1&record_id=',
policy_id, '&link_type=C"',
' target="_blank">Correct</a>'),
# only create update link if it's a new entry
Update = ifelse(
entry_type == "new_entry",
paste0('<a href="https://tummgmt.eu.qualtrics.com/jfe/form/SV_bf6YMWbTpYJAW4l?Q_R=',
record_id, '&record_id=',
policy_id,'&link_type=U"',' target="_blank">Update</a>'), ""),
recorded_date = as.character(recorded_date)) %>%
select(Correct, Update,
corrected,
start, end,
record_id, policy_id,
recorded_date,
ra_name, country, province,
init_country_level, entry_type,
type, description,
target_geog_level, target_region, target_province, target_city,
target_other, target_who_what, target_direction, travel_mechanism,
compliance, enforcer, everything())
## -------------------< format timeline data >--------------------------------
# policy type information
group_data <- select(full_data, id = "group_id", content = "type2", type) %>%
distinct() %>%
filter(!is.na(id))
# timeline data
qdata <- full_data %>%
select(start,
end,
ra_name,
policy_id,
title = "description",
content = "init_country_level",
group = "group_id",
id = "record_id",
country,
province,
city,
entry_type) %>%
mutate(
content = recode(
content,
`No, it is at the national level` = "National",
`Yes, it is at the province/state level` = "Provincial",
`Yes, it is at the city/municipal level` = "City",
`Yes, it is at another governmental level (e.g. county)` = "District"),
end = coalesce(end, lubridate::today()),
content = case_when(
!is.na(province) & is.na(city) ~ paste(content, country,
province, title, sep = "-"),
!is.na(province) & !is.na(city) ~ paste(content, country,
province, title, city, sep = "-"),
is.na(province) & !is.na(city) ~ paste(content, country,
city, sep = "-"),
TRUE ~ paste(content, country, title, sep = "-"))) %>%
filter(!is.na(start), !is.na(group))
# set up policy types for drop downs to ensure data entry is safe
source_cols <- purrr::map(
.x = purrr::set_names(c("type", "country", "province", "target_geog_level",
"compliance", "target_who_what", "target_direction")),
.f = function(x) unique(full_data[[x]]))
# grab most recent entry in data
mostrecent_date <- max(lubridate::as_datetime(full_data$recorded_date),
na.rm = TRUE)
# disconnect from database
dbDisconnect(con)
# user_access_data <- tibble(userid=session$user,
#        accessdate=as.character(lubridate::now()))
# dbWriteTable(con,"corona_users",value=user_access_data,append=T,
#              row.names=F)
update <- environment()
update$count <- 0
runApp('C:/Users/August/OneDrive - Københavns Universitet/Documents/Uni/corona_private/data_validate_shiny')
runApp('C:/Users/August/OneDrive - Københavns Universitet/Documents/Uni/corona_private/data_validate_shiny')
runApp('C:/Users/August/OneDrive - Københavns Universitet/Documents/Uni/corona_private/data_validate_shiny')
runApp()
runApp('C:/Users/August/OneDrive - Københavns Universitet/Documents/Uni/corona_private/data_validate_shiny')
runApp('C:/Users/August/OneDrive - Københavns Universitet/Documents/Uni/corona_private/data_validate_shiny')
runApp('C:/Users/August/OneDrive - Københavns Universitet/Documents/Uni/corona_private/data_validate_shiny')
runApp('C:/Users/August/OneDrive - Københavns Universitet/Documents/Uni/corona_private/data_validate_shiny')
if(!require("devtools")) install.packages("devtools")
devtools::install_github("Guscode/Sentida")
devtools::install_github("Guscode/Sentida")
install.packages("devtools")
devtools::install_github("Guscode/Sentida")
uninstall.packages("glue")
remove.packages("glue")
remove.packages("tidyverse")
library("tidyverse")
library(tidyverse)
devtools::install_github("Guscode/Sentida")
install.packages("Rtools")
devtools::install_github("tidyverse/glue")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
Sys.which("make")
install.packages("jsonlite", type = "source")
pwd
cwd
wd
devtools::install_github("Guscode/Sentida")
#if(!require("devtools")) install.packages("devtools")
install.packages("glue")
library("glue")
devtools::install_github("Guscode/Sentida")
library(Sentida)
Sentida::sentida("jeg hader tandpasta")
Sentida::sentida("jeg elser tandpasta")
Sentida::sentida("jeg elser tandpasta meget")
Sentida::sentida("jeg elser dig meget")
Sentida::sentida("jLad der blive fred.")
Sentida::sentida("Lad der blive fred.")
Sentida::sentida("Lad der blive fred!")
Sentida::sentida("Lad der blive fred!",output = "mean")
Sentida::sentida("Lad der blive fred!",output = "mean", normal = False)
Sentida::sentida("Lad der blive fred!",output = "mean", normal = "False")
Sentida::sentida("Abort er mord",output = "mean")
Sentida::sentida("Colgate er godt og smager dejligt", output = "total")
Sentida::sentida("Colgate er godt og smager mega dejligt", output = "total")
Sentida::sentida("Abort er mord", output = "mean")
sentida("Abort er mord", output = "total")
sentida("Abort er mord", output = "mean")
sentida("Abort er mord", output = "mean")
wd
install.packages("openxlsx")
library(openxlsx)
getwd()
setwd("C:\Users\August\OneDrive - Københavns Universitet\Documents\Uni\Kandidat i Statskundskab\4. semester kandidat\Projekt\FT-project")
df <- openxlsx::read.xlsx("FT_speechdata")
getwd()
setwd("C:\Users\August\OneDrive - Københavns Universitet\Documents\Uni\Kandidat i Statskundskab\4. semester kandidat\Projekt\FT-project")
setwd("C:\\Users\\August\\OneDrive - Københavns Universitet\\Documents\\Uni\\Kandidat i Statskundskab\\4. semester kandidat\\Projekt\\FT-project")
df <- openxlsx::read.xlsx("FT_speechdata")
getwd()
df <- openxlsx::read.xlsx("FT_speechdata.xlsx")
df <- read.csv("FT_speechdata.xlsx")
df <- read.csv("FT_speechdata.csv")
View(df)
df <- read.csv("FT_speechdata.csv", encoding = "UTF-8")
View(df)
View(df)
df <- read.csv("full_df.csv", encoding = "UTF-8")
View(df)
View(df)
df$sentiment_mean = 0
df$sentiment_mean = df$X +1
View(df)
View(df)
df$sentiment_mean = Sentida::sentida(df$tale,output = "mean")
View(df)
View(df)
df$tale
df$X[1]
len(df)
length(df)
rows(df)
nrow(df)
for( i in 1:nrow(df))
print(i)
for( i in 1:nrow(df))
print(i)
for( i in 1:nrow(df)){
print(i){
if(i > 10)
break
}
}
for( i in 1:nrow(df)){
print(i)
if(i == 10){
break
}
}
for( i in 1:nrow(df)){
print(i)
if(i > 10){
break
}
}
for( i in 1:nrow(df)){
print(df$X[i])
if(i == 10){
break
}
}
View(df)
View(df)
for( i in 1:nrow(df)){
print(df$X[i])
print(Sentida::sentida(df$tale[i],output = "mean"))
if(i == 10){
break
}
}
install.packages("svMisc")
library(svMisc)
for( i in 1:nrow(df)){
print(df$X[i])
progress(i)
df$sentiment_mean[i] <- Sentida::sentida(df$tale[i],output = "mean")
df$sentiment_total[i] <- Sentida::sentida(df$tale[i],output = "total")
if(i == 10){
break
}
}
for( i in 1:nrow(df)){
progress(i)
df$sentiment_mean[i] <- Sentida::sentida(df$tale[i],output = "mean")
df$sentiment_total[i] <- Sentida::sentida(df$tale[i],output = "total")
if(i == 10){
break
}
}
for( i in 1:nrow(df)){
progress(i)
df$sentiment_mean[i] <- Sentida::sentida(df$tale[i],output = "mean")
df$sentiment_total[i] <- Sentida::sentida(df$tale[i],output = "total")
}
for( i in 1:nrow(df)){
progress(i,nrow(df))
df$sentiment_mean[i] <- Sentida::sentida(df$tale[i],output = "mean")
df$sentiment_total[i] <- Sentida::sentida(df$tale[i],output = "total")
}
View(df)
View(df)
write.csv(df,"df_sentiment.csv")
